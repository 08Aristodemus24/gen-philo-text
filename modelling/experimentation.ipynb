{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from models.arcs import load_alt_model_a, load_alt_model_b, load_inf_model, GenPhiloText\n",
    "from utilities.loaders import load_file\n",
    "from utilities.preprocessors import preprocess, map_value_to_index, init_sequences\n",
    "from utilities.visualizers import export_results\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy as cce_loss\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, CategoricalCrossentropy as cce_metric\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import one_hot\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_file('./data/notes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A simple idea “What is the meaning of life?”\\nI asked as I learned through the works of Camus? \\nOne step down, I felt a yearning of meaning in this world.\\nIn this yearning I stumbled upon eastern philosophy;\\nIkigai as the Japanese philosophers called it was a considerable way for me to find meaning at that certain point in my life. \\nFollowed then another idea, a leap of faith as Kierkegaard would call it, yet I had no idea this was his idea. \\nCalm followed after the storm, and then I took another'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226750"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '´',\n",
       " 'ç',\n",
       " 'é',\n",
       " 'ï',\n",
       " '–',\n",
       " '—',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '…']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(corpus)))\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing corpus\n",
    "* replace quotation marks like this '“'/'”' with this instead '\"'\n",
    "* replace single quotation marks like this '‘'/'’' with ''' instead\n",
    "* replace this hyphen '–' with this hyphen '—'\n",
    "* lowercase all words (for now)\n",
    "* replace 3 consecutive '.' with  '…' instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a simple idea \"what is the meaning of life?\"\\ni asked as i learned through the works of camus? \\none step down, i felt a yearning of meaning in this world.\\nin this yearning i stumbled upon eastern philosophy;\\nikigai as the japanese philosophers called it was a considerable way for me to find meaning at that certain point in my life. \\nfollowed then another idea, a leap of faith as kierkegaard would call it, yet i had no idea this was his idea. \\ncalm followed after the storm, and then i took another step down. \\nalthough i know the next idea i had was because of the idea of meaninglessness by camus, i was not sure where this exact idea started — the idea of right and wrong, good and evil. this one step down i would say was worse than the one before, as it forced me to think deeper than ever, thereby not knowingly using regression to find the answers i was seeking. if i was to be caveman, regress to a less developed state of man, a blank slate as i call it, how would i invent good and evil? writing was a way i got to express what i was thinking as the opposed action of not writing it was surely a quick way to let my idea that i thought was important slip away. writing i quickly knew how the idea of good and evil came to be, how it was birthed and willed into this world. suffering i discovered was the simple answer. man i believe by his instincts truly is afraid of suffering, at least at first i claim. and it is the infliction of pain and agony upon another man is what i believed stemmed the idea of evil, as opposed to the simple actions of affection by physical touch or compassion — as cain brought upon abel. one step down again and i confess even i questioned my own virtues, it being discipline, courage, self-respect, compassion, empathy, selflessness, in my psyche the excavations went deeper, as i thought of reasons why i had to live by these virtues — most especially courage and discipline the reason being because these we are  the hardest to take into action. a simple'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = preprocess(corpus)\n",
    "corpus[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '´',\n",
       " 'ç',\n",
       " 'é',\n",
       " 'ï',\n",
       " '—',\n",
       " '…']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(corpus)))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique = len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating mapper from a unique character to its respective index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = map_value_to_index(chars, len(chars), 0)\n",
    "idx_to_char = map_value_to_index(chars, len(chars), 0, inverted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " '(': 6,\n",
       " ')': 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '/': 11,\n",
       " '0': 12,\n",
       " '1': 13,\n",
       " '2': 14,\n",
       " '3': 15,\n",
       " '4': 16,\n",
       " '6': 17,\n",
       " '7': 18,\n",
       " '8': 19,\n",
       " '9': 20,\n",
       " ':': 21,\n",
       " ';': 22,\n",
       " '?': 23,\n",
       " 'a': 24,\n",
       " 'b': 25,\n",
       " 'c': 26,\n",
       " 'd': 27,\n",
       " 'e': 28,\n",
       " 'f': 29,\n",
       " 'g': 30,\n",
       " 'h': 31,\n",
       " 'i': 32,\n",
       " 'j': 33,\n",
       " 'k': 34,\n",
       " 'l': 35,\n",
       " 'm': 36,\n",
       " 'n': 37,\n",
       " 'o': 38,\n",
       " 'p': 39,\n",
       " 'q': 40,\n",
       " 'r': 41,\n",
       " 's': 42,\n",
       " 't': 43,\n",
       " 'u': 44,\n",
       " 'v': 45,\n",
       " 'w': 46,\n",
       " 'x': 47,\n",
       " 'y': 48,\n",
       " 'z': 49,\n",
       " '´': 50,\n",
       " 'ç': 51,\n",
       " 'é': 52,\n",
       " 'ï': 53,\n",
       " '—': 54,\n",
       " '…': 55}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '\"',\n",
       " 4: '&',\n",
       " 5: \"'\",\n",
       " 6: '(',\n",
       " 7: ')',\n",
       " 8: ',',\n",
       " 9: '-',\n",
       " 10: '.',\n",
       " 11: '/',\n",
       " 12: '0',\n",
       " 13: '1',\n",
       " 14: '2',\n",
       " 15: '3',\n",
       " 16: '4',\n",
       " 17: '6',\n",
       " 18: '7',\n",
       " 19: '8',\n",
       " 20: '9',\n",
       " 21: ':',\n",
       " 22: ';',\n",
       " 23: '?',\n",
       " 24: 'a',\n",
       " 25: 'b',\n",
       " 26: 'c',\n",
       " 27: 'd',\n",
       " 28: 'e',\n",
       " 29: 'f',\n",
       " 30: 'g',\n",
       " 31: 'h',\n",
       " 32: 'i',\n",
       " 33: 'j',\n",
       " 34: 'k',\n",
       " 35: 'l',\n",
       " 36: 'm',\n",
       " 37: 'n',\n",
       " 38: 'o',\n",
       " 39: 'p',\n",
       " 40: 'q',\n",
       " 41: 'r',\n",
       " 42: 's',\n",
       " 43: 't',\n",
       " 44: 'u',\n",
       " 45: 'v',\n",
       " 46: 'w',\n",
       " 47: 'x',\n",
       " 48: 'y',\n",
       " 49: 'z',\n",
       " 50: '´',\n",
       " 51: 'ç',\n",
       " 52: 'é',\n",
       " 53: 'ï',\n",
       " 54: '—',\n",
       " 55: '…'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  1, 42, ..., 28,  1, 42],\n",
       "       [ 1, 42, 32, ...,  1, 42, 43],\n",
       "       [42, 32, 36, ..., 42, 43, 28],\n",
       "       ...,\n",
       "       [38, 41,  1, ..., 28, 35, 32],\n",
       "       [41,  1, 43, ..., 35, 32, 28],\n",
       "       [ 1, 43, 41, ..., 32, 28, 29]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_time_steps = 100\n",
    "X, Y = init_sequences(corpus, char_to_idx, T_x=n_time_steps)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 28, 39, ..., 28, 29, 10])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert Y data's indeces to their one hot vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(226861, 56), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = one_hot(Y, depth=n_unique)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(56,), dtype=float32, numpy=\n",
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226861"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of examples\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate model with set architecture of generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 64\n",
    "n_a = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 64)           3584      \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100, 32)           12416     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100, 32)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 56)                1848      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 56)               224       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 56)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,392\n",
      "Trainable params: 26,280\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_alt_model_b(n_unique=n_unique, T_x=n_time_steps, emb_dim=emb_dim, n_a=n_a, keep_prob=0.8, lambda_=0.1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide loss, optimizer, and metrics for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "loss = cce_loss()\n",
    "metrics = [CategoricalAccuracy(), cce_metric()]\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and checkpoint weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"./weights/weights-improvement-{epoch:02d}-{categorical_accuracy:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(weights_path, monitor='categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 3.8312 - categorical_accuracy: 0.1611 - categorical_crossentropy: 3.7688\n",
      "Epoch 1: categorical_accuracy improved from -inf to 0.16113, saving model to ./weights\\weights-improvement-01-0.1611.hdf5\n",
      "111/111 [==============================] - 135s 1s/step - loss: 3.8312 - categorical_accuracy: 0.1611 - categorical_crossentropy: 3.7688\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 3.3464 - categorical_accuracy: 0.2308 - categorical_crossentropy: 3.3093\n",
      "Epoch 2: categorical_accuracy improved from 0.16113 to 0.23080, saving model to ./weights\\weights-improvement-02-0.2308.hdf5\n",
      "111/111 [==============================] - 131s 1s/step - loss: 3.3464 - categorical_accuracy: 0.2308 - categorical_crossentropy: 3.3093\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 3.0289 - categorical_accuracy: 0.2773 - categorical_crossentropy: 2.9926\n",
      "Epoch 3: categorical_accuracy improved from 0.23080 to 0.27734, saving model to ./weights\\weights-improvement-03-0.2773.hdf5\n",
      "111/111 [==============================] - 132s 1s/step - loss: 3.0289 - categorical_accuracy: 0.2773 - categorical_crossentropy: 2.9926\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.8527 - categorical_accuracy: 0.2984 - categorical_crossentropy: 2.8173\n",
      "Epoch 4: categorical_accuracy improved from 0.27734 to 0.29844, saving model to ./weights\\weights-improvement-04-0.2984.hdf5\n",
      "111/111 [==============================] - 132s 1s/step - loss: 2.8527 - categorical_accuracy: 0.2984 - categorical_crossentropy: 2.8173\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.7271 - categorical_accuracy: 0.3154 - categorical_crossentropy: 2.6920\n",
      "Epoch 5: categorical_accuracy improved from 0.29844 to 0.31541, saving model to ./weights\\weights-improvement-05-0.3154.hdf5\n",
      "111/111 [==============================] - 130s 1s/step - loss: 2.7271 - categorical_accuracy: 0.3154 - categorical_crossentropy: 2.6920\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.6312 - categorical_accuracy: 0.3241 - categorical_crossentropy: 2.5964\n",
      "Epoch 6: categorical_accuracy improved from 0.31541 to 0.32409, saving model to ./weights\\weights-improvement-06-0.3241.hdf5\n",
      "111/111 [==============================] - 131s 1s/step - loss: 2.6312 - categorical_accuracy: 0.3241 - categorical_crossentropy: 2.5964\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.5517 - categorical_accuracy: 0.3324 - categorical_crossentropy: 2.5167\n",
      "Epoch 7: categorical_accuracy improved from 0.32409 to 0.33242, saving model to ./weights\\weights-improvement-07-0.3324.hdf5\n",
      "111/111 [==============================] - 132s 1s/step - loss: 2.5517 - categorical_accuracy: 0.3324 - categorical_crossentropy: 2.5167\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.4835 - categorical_accuracy: 0.3405 - categorical_crossentropy: 2.4478\n",
      "Epoch 8: categorical_accuracy improved from 0.33242 to 0.34053, saving model to ./weights\\weights-improvement-08-0.3405.hdf5\n",
      "111/111 [==============================] - 138s 1s/step - loss: 2.4835 - categorical_accuracy: 0.3405 - categorical_crossentropy: 2.4478\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.4249 - categorical_accuracy: 0.3463 - categorical_crossentropy: 2.3884\n",
      "Epoch 9: categorical_accuracy improved from 0.34053 to 0.34634, saving model to ./weights\\weights-improvement-09-0.3463.hdf5\n",
      "111/111 [==============================] - 136s 1s/step - loss: 2.4249 - categorical_accuracy: 0.3463 - categorical_crossentropy: 2.3884\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.3761 - categorical_accuracy: 0.3537 - categorical_crossentropy: 2.3395\n",
      "Epoch 10: categorical_accuracy improved from 0.34634 to 0.35367, saving model to ./weights\\weights-improvement-10-0.3537.hdf5\n",
      "111/111 [==============================] - 133s 1s/step - loss: 2.3761 - categorical_accuracy: 0.3537 - categorical_crossentropy: 2.3395\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.3323 - categorical_accuracy: 0.3612 - categorical_crossentropy: 2.2957\n",
      "Epoch 11: categorical_accuracy improved from 0.35367 to 0.36120, saving model to ./weights\\weights-improvement-11-0.3612.hdf5\n",
      "111/111 [==============================] - 133s 1s/step - loss: 2.3323 - categorical_accuracy: 0.3612 - categorical_crossentropy: 2.2957\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.2984 - categorical_accuracy: 0.3642 - categorical_crossentropy: 2.2618\n",
      "Epoch 12: categorical_accuracy improved from 0.36120 to 0.36417, saving model to ./weights\\weights-improvement-12-0.3642.hdf5\n",
      "111/111 [==============================] - 129s 1s/step - loss: 2.2984 - categorical_accuracy: 0.3642 - categorical_crossentropy: 2.2618\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.2649 - categorical_accuracy: 0.3698 - categorical_crossentropy: 2.2285\n",
      "Epoch 13: categorical_accuracy improved from 0.36417 to 0.36981, saving model to ./weights\\weights-improvement-13-0.3698.hdf5\n",
      "111/111 [==============================] - 130s 1s/step - loss: 2.2649 - categorical_accuracy: 0.3698 - categorical_crossentropy: 2.2285\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.2382 - categorical_accuracy: 0.3749 - categorical_crossentropy: 2.2018\n",
      "Epoch 14: categorical_accuracy improved from 0.36981 to 0.37488, saving model to ./weights\\weights-improvement-14-0.3749.hdf5\n",
      "111/111 [==============================] - 129s 1s/step - loss: 2.2382 - categorical_accuracy: 0.3749 - categorical_crossentropy: 2.2018\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.2123 - categorical_accuracy: 0.3794 - categorical_crossentropy: 2.1761\n",
      "Epoch 15: categorical_accuracy improved from 0.37488 to 0.37940, saving model to ./weights\\weights-improvement-15-0.3794.hdf5\n",
      "111/111 [==============================] - 129s 1s/step - loss: 2.2123 - categorical_accuracy: 0.3794 - categorical_crossentropy: 2.1761\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.1916 - categorical_accuracy: 0.3826 - categorical_crossentropy: 2.1555\n",
      "Epoch 16: categorical_accuracy improved from 0.37940 to 0.38261, saving model to ./weights\\weights-improvement-16-0.3826.hdf5\n",
      "111/111 [==============================] - 128s 1s/step - loss: 2.1916 - categorical_accuracy: 0.3826 - categorical_crossentropy: 2.1555\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.1724 - categorical_accuracy: 0.3871 - categorical_crossentropy: 2.1363\n",
      "Epoch 17: categorical_accuracy improved from 0.38261 to 0.38711, saving model to ./weights\\weights-improvement-17-0.3871.hdf5\n",
      "111/111 [==============================] - 128s 1s/step - loss: 2.1724 - categorical_accuracy: 0.3871 - categorical_crossentropy: 2.1363\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.1505 - categorical_accuracy: 0.3909 - categorical_crossentropy: 2.1147\n",
      "Epoch 18: categorical_accuracy improved from 0.38711 to 0.39093, saving model to ./weights\\weights-improvement-18-0.3909.hdf5\n",
      "111/111 [==============================] - 128s 1s/step - loss: 2.1505 - categorical_accuracy: 0.3909 - categorical_crossentropy: 2.1147\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.1371 - categorical_accuracy: 0.3930 - categorical_crossentropy: 2.1010\n",
      "Epoch 19: categorical_accuracy improved from 0.39093 to 0.39298, saving model to ./weights\\weights-improvement-19-0.3930.hdf5\n",
      "111/111 [==============================] - 128s 1s/step - loss: 2.1371 - categorical_accuracy: 0.3930 - categorical_crossentropy: 2.1010\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 2.1206 - categorical_accuracy: 0.3956 - categorical_crossentropy: 2.0845\n",
      "Epoch 20: categorical_accuracy improved from 0.39298 to 0.39562, saving model to ./weights\\weights-improvement-20-0.3956.hdf5\n",
      "111/111 [==============================] - 128s 1s/step - loss: 2.1206 - categorical_accuracy: 0.3956 - categorical_crossentropy: 2.0845\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=20, batch_size=2048, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results(history, ['loss'], image_only=False)\n",
    "export_results(history, ['categorical_accuracy'], image_only=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phil-jurisprudence-recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
