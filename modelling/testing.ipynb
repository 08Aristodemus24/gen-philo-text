{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will aim to use the trained models weights and load it on the inference model to generate predictions and novel sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from models.arcs import generate, GenPhiloTextA\n",
    "from utilities.loaders import load_file\n",
    "from utilities.preprocessors import preprocess, get_chars, map_value_to_index, decode_predictions\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_file('./data/notes.txt')\n",
    "corpus = preprocess(corpus)\n",
    "chars = get_chars(corpus)\n",
    "char_to_idx = map_value_to_index(chars)\n",
    "idx_to_char = map_value_to_index(chars, inverted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " '\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '´',\n",
       " 'ç',\n",
       " 'é',\n",
       " 'ï',\n",
       " '—',\n",
       " '…']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique = len(char_to_idx.get_vocabulary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare same hyper params used in training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "n_a = 512\n",
    "T_x = 100\n",
    "dense_layers_dims = [n_unique]\n",
    "batch_size = 128\n",
    "alpha = 1e-3\n",
    "lambda_ = 0.8\n",
    "drop_prob = 0.4\n",
    "normalize = False\n",
    "n_epochs =  100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare sample input to build inference model and access .summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = tf.random.uniform(shape=(1, T_x), minval=0, maxval=n_unique - 1, dtype=tf.int32)\n",
    "sample_h = tf.zeros(shape=(1, n_a))\n",
    "sample_c = tf.zeros(shape=(1, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redeclare architecture by passing the same hyper params used in training and then load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100, 57), dtype=float32, numpy=\n",
       "array([[[-0.00540989, -0.00015633,  0.00198572, ..., -0.00101178,\n",
       "         -0.00120615, -0.00105561],\n",
       "        [-0.00121182,  0.00344092,  0.00260131, ..., -0.00104574,\n",
       "          0.00100229,  0.00843915],\n",
       "        [ 0.00267117,  0.01026063,  0.00286845, ...,  0.0010662 ,\n",
       "          0.00959603,  0.00309708],\n",
       "        ...,\n",
       "        [-0.0080949 ,  0.0046614 , -0.00214528, ..., -0.00063614,\n",
       "         -0.00011534, -0.00825164],\n",
       "        [-0.010578  ,  0.00026269, -0.00389015, ..., -0.00127934,\n",
       "          0.00208991, -0.00692616],\n",
       "        [ 0.00742032, -0.00104589, -0.00278196, ..., -0.00734997,\n",
       "         -0.00323965, -0.00666001]]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = GenPhiloTextA(emb_dim=emb_dim, n_a=n_a, n_unique=n_unique, dense_layers_dims=dense_layers_dims, drop_prob=drop_prob, normalize=normalize)\n",
    "saved_model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 110, 57), dtype=float32, numpy=\n",
       "array([[[-0.99894917, -0.05772941,  0.7268927 , ..., -0.9724182 ,\n",
       "         -0.9088973 , -0.94427675],\n",
       "        [-1.1066761 , -0.06039706,  1.2362472 , ..., -1.0789745 ,\n",
       "         -0.9914653 , -1.0287079 ],\n",
       "        [-1.3930281 , -0.06760611,  2.5738266 , ..., -1.3620644 ,\n",
       "         -1.2109687 , -1.2518831 ],\n",
       "        ...,\n",
       "        [-1.5018518 , -0.07016251,  3.0781136 , ..., -1.4694932 ,\n",
       "         -1.2944503 , -1.3362739 ],\n",
       "        [-1.5018518 , -0.07016251,  3.0781136 , ..., -1.4694932 ,\n",
       "         -1.2944503 , -1.3362739 ],\n",
       "        [-1.5018518 , -0.07016251,  3.0781136 , ..., -1.4694932 ,\n",
       "         -1.2944503 , -1.3362739 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input = tf.random.uniform(shape=(1, T_x + 10), minval=0, maxval=n_unique - 1, dtype=tf.int32)\n",
    "saved_model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gen_philo_text_a_1/character-lookup/embeddings:0' shape=(57, 256) dtype=float32, numpy=\n",
       " array([[ 0.02210325,  0.03110288, -0.037651  , ...,  0.04402642,\n",
       "          0.02510992,  0.03947211],\n",
       "        [ 0.04615412,  0.01848548, -0.00974838, ...,  0.02000702,\n",
       "         -0.00067936, -0.01324873],\n",
       "        [-0.02544125, -0.02470543,  0.02690467, ..., -0.03230782,\n",
       "          0.02221466, -0.03676935],\n",
       "        ...,\n",
       "        [-0.01678227, -0.01716178,  0.02083695, ..., -0.02941795,\n",
       "          0.00815401, -0.0451331 ],\n",
       "        [ 0.02076752,  0.00204693, -0.04578961, ..., -0.00936799,\n",
       "         -0.03868567,  0.02656769],\n",
       "        [ 0.0333526 ,  0.0111682 , -0.04376334, ...,  0.00224353,\n",
       "          0.01670386,  0.02239729]], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/lstm-layer/lstm_cell/kernel:0' shape=(256, 2048) dtype=float32, numpy=\n",
       " array([[ 0.01321833,  0.0041265 ,  0.04305574, ..., -0.02544646,\n",
       "          0.05080582,  0.03523806],\n",
       "        [ 0.04631002,  0.00780468, -0.02287318, ...,  0.01756121,\n",
       "         -0.03755831,  0.036109  ],\n",
       "        [-0.00387426,  0.00605527, -0.01828033, ...,  0.0098812 ,\n",
       "          0.02842961,  0.02465475],\n",
       "        ...,\n",
       "        [-0.04117899,  0.0242662 ,  0.00342479, ...,  0.0360747 ,\n",
       "         -0.0052505 , -0.0156762 ],\n",
       "        [ 0.02459451,  0.03154452,  0.00584499, ..., -0.04707269,\n",
       "          0.00307961, -0.03626665],\n",
       "        [-0.0189684 , -0.04938743, -0.04198225, ..., -0.02285577,\n",
       "         -0.03017406, -0.03176616]], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/lstm-layer/lstm_cell/recurrent_kernel:0' shape=(512, 2048) dtype=float32, numpy=\n",
       " array([[-0.02554977, -0.01581968,  0.02152698, ..., -0.06900321,\n",
       "          0.00135111, -0.02865014],\n",
       "        [ 0.0190356 ,  0.00582206,  0.02336759, ..., -0.01406528,\n",
       "         -0.01797377,  0.00942439],\n",
       "        [-0.01154353,  0.04806959,  0.01596236, ..., -0.00521035,\n",
       "          0.01233424,  0.03749494],\n",
       "        ...,\n",
       "        [-0.02121949, -0.01069889, -0.02100066, ...,  0.00700582,\n",
       "          0.00118967,  0.06214419],\n",
       "        [ 0.01549007,  0.00710232, -0.0217856 , ...,  0.03772371,\n",
       "          0.00635601, -0.01231971],\n",
       "        [ 0.03380691, -0.01950353,  0.06835391, ...,  0.01249654,\n",
       "          0.04342316, -0.03455705]], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/lstm-layer/lstm_cell/bias:0' shape=(2048,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/dense-layer-0/kernel:0' shape=(512, 57) dtype=float32, numpy=\n",
       " array([[-0.10017096,  0.06812693,  0.08627254, ...,  0.02231169,\n",
       "          0.0044702 ,  0.00867834],\n",
       "        [ 0.0211122 , -0.01446387,  0.0274915 , ...,  0.05641863,\n",
       "         -0.00359566,  0.06942071],\n",
       "        [ 0.04867955,  0.08554202,  0.04230288, ..., -0.01086883,\n",
       "          0.03672713, -0.03251121],\n",
       "        ...,\n",
       "        [ 0.01310511,  0.05907205, -0.07222673, ...,  0.00435305,\n",
       "         -0.02532952, -0.08609668],\n",
       "        [ 0.0118239 ,  0.0566318 ,  0.01402943, ...,  0.06063534,\n",
       "          0.06180221, -0.0726614 ],\n",
       "        [-0.0718495 , -0.05387419, -0.06114892, ..., -0.03099871,\n",
       "          0.03946719, -0.07716648]], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/dense-layer-0/bias:0' shape=(57,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gen_philo_text_a_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " character-lookup (Embeddin  multiple                  14592     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " lstm-layer (LSTM)           multiple                  1574912   \n",
      "                                                                 \n",
      " dense-layer-0 (Dense)       multiple                  29241     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1618745 (6.18 MB)\n",
      "Trainable params: 1618745 (6.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.load_weights(filepath='./saved/weights/notes_gen_philo_text_a_100_3.0300.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gen_philo_text_a_1/character-lookup/embeddings:0' shape=(57, 256) dtype=float32, numpy=\n",
       " array([[ 1.5778426e-33,  8.5969997e-32,  9.0914019e-33, ...,\n",
       "          2.6084619e-31,  1.2379388e-31,  6.8241091e-32],\n",
       "        [-1.7392811e-06,  3.5470998e-06, -1.1924452e-06, ...,\n",
       "         -1.8112476e-06,  1.5420478e-06, -1.3949349e-06],\n",
       "        [-2.6034151e-05,  2.2033426e-05, -1.9344105e-05, ...,\n",
       "         -2.8262819e-05,  2.7131497e-05, -2.2557864e-05],\n",
       "        ...,\n",
       "        [-8.5676251e-11,  1.9831338e-11,  8.3653984e-10, ...,\n",
       "         -1.2872679e-10,  1.4269575e-11,  2.9089064e-10],\n",
       "        [-5.6282662e-08, -9.0218379e-08, -1.5125519e-08, ...,\n",
       "          1.4084819e-07, -4.6915076e-08, -5.9459062e-08],\n",
       "        [ 5.1603475e-08, -8.0799829e-09, -5.9060262e-08, ...,\n",
       "         -8.0631750e-08, -6.6796417e-08, -9.6390124e-08]], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/lstm-layer/lstm_cell/kernel:0' shape=(256, 2048) dtype=float32, numpy=\n",
       " array([[ 0.0263859 , -0.03103871,  0.01192956, ..., -0.0129817 ,\n",
       "         -0.03242833, -0.0391698 ],\n",
       "        [ 0.05033895, -0.03943883,  0.02814242, ..., -0.00039441,\n",
       "          0.0285701 , -0.01991814],\n",
       "        [ 0.01369799, -0.00986184, -0.05510566, ..., -0.03393815,\n",
       "         -0.03612003,  0.00776799],\n",
       "        ...,\n",
       "        [-0.02675014, -0.05246468, -0.03946001, ...,  0.02910612,\n",
       "         -0.03787148,  0.07083829],\n",
       "        [ 0.0355772 ,  0.01816593, -0.03125739, ..., -0.00207981,\n",
       "          0.010299  ,  0.00972482],\n",
       "        [-0.01448291,  0.00698018, -0.04719383, ...,  0.0159514 ,\n",
       "         -0.04067192,  0.04942426]], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/lstm-layer/lstm_cell/recurrent_kernel:0' shape=(512, 2048) dtype=float32, numpy=\n",
       " array([[ 0.02558143,  0.05126306,  0.02020243, ...,  0.04479393,\n",
       "          0.0024286 ,  0.0651344 ],\n",
       "        [-0.01708457,  0.05732007,  0.07156777, ...,  0.01299669,\n",
       "          0.087997  ,  0.00398771],\n",
       "        [ 0.04374947,  0.08568013,  0.08955891, ..., -0.03420319,\n",
       "          0.02005105,  0.01599265],\n",
       "        ...,\n",
       "        [-0.0153836 , -0.09198741, -0.03696572, ..., -0.00307061,\n",
       "         -0.04691401, -0.05609098],\n",
       "        [ 0.03702481,  0.2319954 ,  0.16468684, ...,  0.02995122,\n",
       "          0.0804543 ,  0.09673621],\n",
       "        [-0.03067177,  0.04118955,  0.00973033, ..., -0.01930979,\n",
       "          0.04990653,  0.00230697]], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/lstm-layer/lstm_cell/bias:0' shape=(2048,) dtype=float32, numpy=\n",
       " array([0.071105  , 0.16393386, 0.41605067, ..., 0.10917301, 0.52511847,\n",
       "        0.04490369], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/dense-layer-0/kernel:0' shape=(512, 57) dtype=float32, numpy=\n",
       " array([[-1.1046523e-03,  4.4079694e-05,  5.1689139e-03, ...,\n",
       "         -1.1019871e-03, -8.5315004e-04, -9.5110177e-04],\n",
       "        [-1.1112882e-03,  9.0452479e-05,  5.2525522e-03, ...,\n",
       "         -1.1092033e-03, -8.6153229e-04, -8.7889004e-04],\n",
       "        [-1.1148278e-03, -4.5198901e-04,  5.4436876e-03, ...,\n",
       "         -1.1140627e-03, -8.7307714e-04, -1.0893450e-03],\n",
       "        ...,\n",
       "        [ 1.1092310e-03, -3.3278993e-05, -5.2868933e-03, ...,\n",
       "          1.1739274e-03,  8.6100819e-04,  8.3360681e-04],\n",
       "        [-1.1160319e-03,  6.5825720e-05,  5.4411809e-03, ...,\n",
       "         -1.1088678e-03, -8.6696248e-04, -8.3124259e-04],\n",
       "        [-1.0969219e-03,  8.1233164e-05,  5.0352062e-03, ...,\n",
       "         -1.0989138e-03, -8.4097241e-04, -9.1815088e-04]], dtype=float32)>,\n",
       " <tf.Variable 'gen_philo_text_a_1/dense-layer-0/bias:0' shape=(57,) dtype=float32, numpy=\n",
       " array([-0.98459494, -0.05734346,  0.6583223 , -0.9192596 , -0.88379365,\n",
       "        -0.97339123, -0.97492695, -0.9685314 , -0.97812307, -0.00622913,\n",
       "        -0.95200515, -0.34435037, -0.9603944 , -0.9646638 , -1.0054103 ,\n",
       "        -0.9621481 , -0.9877688 , -1.0069875 , -1.0050209 , -0.9829094 ,\n",
       "        -0.98747766, -0.89543474, -1.0011859 , -0.96650934, -0.92178345,\n",
       "         0.8574182 ,  0.34266204,  0.63459516,  0.76823884,  0.8534486 ,\n",
       "         0.7194565 ,  0.5242003 ,  0.87957793,  0.88946056, -0.9038104 ,\n",
       "        -0.40608457,  0.8090775 ,  0.65698814,  0.86579156,  0.8823662 ,\n",
       "         0.20393847, -0.9292775 ,  0.86745876,  0.8326506 ,  0.8549706 ,\n",
       "         0.71884435,  0.21992548,  0.56595194, -0.9462897 ,  0.52284986,\n",
       "        -0.9386598 , -0.9674835 , -0.9831326 , -0.9863472 , -0.95820504,\n",
       "        -0.89787054, -0.9328989 ], dtype=float32)>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.trainable_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract trainable layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_predictions(pred_ids, idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-philo-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
